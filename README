NAME: Forrest Burton
EMAIL: burton.forrest10@gmail.com
ID: 005324612
SLIPDAYS: 2

QUESTION 2.1.1 - causing conflicts:
Why does it take many iterations before errors are seen?
It takes many iterations before errors are seen because race conditions are more likely to occur as the number of threads increases. This is 
because a race condition occurs when multiple threads are trying to execute the same section of code. Although, if the number of iterations 
is a small number, then the thread can finish all of its iterations before the next thread is created and has a chance to execute the code. 

Why does a significantly smaller number of iterations so seldom fail?
Basically when the time it takes to complete the iterations outweighs the time to create a thread, errors will occur. The time to create a 
thread will generally be greater than the time to complete a significantly smaller number of iterations which is why it will rarely fail. 


QUESTION 2.1.2 - cost of yielding:
Why are the --yield runs so much slower?
The --yield runs much slower because the sched_yield() function temporarily makes each thread give up its time slice and therefore its control of 
the CPU,therefore it takes much more time to execute the add() function for all the threads since they are giving up time slices. Waking up and
sleeping threads adds a lot of overhead.

Where is the additional time going?
The additional time is going towards threads "yielding" the CPU or giving up their time slice 

Is it possible to get valid per-operation timings if we are using the --yield option?
If so, explain how. If not, explain why not.
It is not possible to get valid per-operation timings while using the --yield option because it is impossible to know the exact time it takes for 
context switching, and therefore cannot factor this time out and figure out just the per-operations timings. 


QUESTION 2.1.3 - measurement errors:
Why does the average cost per operation drop with increasing iterations?
The average cost per operation drops with increasing iterations because iterations take up less overhead than creating a thread does. But as the 
number of iteartions increases it makes the time it takes to create a thread relatively less siginificant because a thread creation is spread out
betweeen all the iterations. 

If the cost per iteration is a function of the number of iterations, how do we know how many iterations to run (or what the "correct" cost is)?
We can determine the "correct" cost by greatly increasing the number of iterations. As the number of iterations approaches postive infinity, the 
cost per iteration becomes insignificant and the curve flatens out, giving is the "correct" cost. 


QUESTION 2.1.4 - costs of serialization:
Why do all of the options perform similarly for low numbers of threads?
The options perform similarly for low number of threads because as discussed above in QUESTION 2.1.1, race condition problems rarely occur with a 
low number of threads. So since there is no much competition for the shared recource all the options perform similarly. 

Why do the three protected operations slow down as the number of threads rises?
The operations slow down as the number of threads rises because there is more competition for the shared recourse which causes the threads to on 
average wait more for locks to be released. This makes threads spend more time waiting to perform operations. 


QUESTION 2.2.1 - scalability of Mutex
Compare the variation in time per mutex-protected operation vs the number of threads in Part-1 (adds) and Part-2 (sorted lists).
Comment on the general shapes of the curves, and explain why they have this shape.
Comment on the relative rates of increase and differences in the shapes of the curves, and offer an explanation for these differences.
For the graph for Part-1, the time per mutex-protected operation appears to plateu as the number of threads increases. This is in contrast 
to the graph for Part-2, which time per mutex-protected operation appears to increase linearly as the number of threads increases. An explanation
for this could be the fact that operations on linked lists such as searching, insertion, deletion, and getting length all have a time complexity
of O(n) while the time complexity for additionn is O(1). This would explain why Graph-1 appears to plateu while Graph-2 increases linearly. 

QUESTION 2.2.2 - scalability of spin locks
Compare the variation in time per protected operation vs the number of threads for list operations protected by Mutex vs Spin locks. Comment on 
the general shapes of the curves, and explain why they have this shape.
Comment on the relative rates of increase and differences in the shapes of the curves, and offer an explanation for these differences.
The trend of the time per protected operation vs number fo threads for Mutex and Spin locks resemble each other closely. In the graphs,
they both increase linearly which is likely due to the time complexity of most list operations being O(N) as discussed above. Although,
in the graph the time per protected opeartion for mutexes generally appears to be slightly less than that of Spin Locks as the number of 
threads increases. 

The tarball contains:
lab2_add.c:   C program which contains a shared variable add function. The program has the following options: --threads, --iterations, --sync.
              The progam outputs a CSV including: name of the test, number of threads, number of iterations, number of operations,
              total run time (in nanoseconds), average time per operation (in nanoseconds), and the total at end of the run
lab2_list.c:  C program which outputs statistics after initializing an empty list and has the following options: --threads, --iterations, 
              --yield, --sync. The program creates threads then records stastics. The program ouptuts a CSV including: name of test, number of
              threads number of iterations, number of lists, total number of operations performed, total run time (nanoseconds), average 
              time per operation (nanoseconds).
SortedList.c: C module which contains the following methods for implementing a double linked list: insert, delete, lookup, and length
SortedList.h: Header file which describes the API for the double linked list operation
Makefile:     contains options default build, dist, clean, tests, and graphs

Recourses:
**Discussion 1B very helpful
Converting string to int - https://stackoverflow.com/questions/7021725/how-to-convert-a-string-to-integer-in-c
Multithreading in C - https://www.geeksforgeeks.org/multithreading-c-2/
pthread_create(3) man page - https://man7.org/linux/man-pages/man3/pthread_create.3.html
timespec error - https://stackoverflow.com/questions/11153334/timespec-not-found-in-time-h
clock_gettime(3) man page - https://linux.die.net/man/3/clock_gettime
pthread_mutex_init(3) man page - https://linux.die.net/man/3/pthread_mutex_init
pthread_mutex_lock(3) man page - https://linux.die.net/man/3/pthread_mutex_lock
copying string to buffer - https://stackoverflow.com/questions/25838628/copying-string-literals-in-c-into-an-character-array/25838679
strcat in C - https://www.holbertonschool.com/coding-resource-strcat-in-c
fprintf vs printf - https://stackoverflow.com/questions/4627330/difference-between-fprintf-printf-and-sprintf
weird void* function error - https://stackoverflow.com/questions/28018045/error-in-pointer-multithread-expected-void-void-but-argument-is-of
undefined reference to pthread - https://stackoverflow.com/questions/1662909/undefined-reference-to-pthread-create-in-linux
generating random integers - https://stackoverflow.com/questions/1202687/how-do-i-get-a-specific-range-of-numbers-from-rand
https://www.geeksforgeeks.org/generating-random-number-range-c/
valgrind help - https://stackoverflow.com/questions/5134891/how-do-i-use-valgrind-to-find-memory-leaks
https://stackoverflow.com/questions/23791398/is-not-stackd-mallocd-or-recently-freed-when-all-the-variables-is-used/23802904